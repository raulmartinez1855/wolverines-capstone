{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2020,2021,2022,2023]\n",
    "conferences = ['ACC', 'Big10', 'Big12', 'SEC', 'PAC12']\n",
    "\n",
    "for year in years:\n",
    "    for con in conferences:\n",
    "\n",
    "        #Player Stats by Season\n",
    "        p_stats_season = pd.read_csv(f'Player Stats/Player Stats By Season {con} {year}.csv')\n",
    "        #Remove 'Team' Player\n",
    "        p_stats_season = p_stats_season[p_stats_season['Player'] != ' Team']\n",
    "\n",
    "        #Group Player Stats by PlayerId\n",
    "        p_stats_season = p_stats_season[['PlayerId', 'StatType', 'Stat']].groupby(['PlayerId', 'StatType']).sum().unstack()\n",
    "        p_stats_season.columns = p_stats_season.columns.droplevel(0)\n",
    "        p_stats_season.reset_index(inplace = True)\n",
    "        p_stats_season = p_stats_season.rename_axis(None, axis=1)\n",
    "        p_stats_season.index = p_stats_season.index.map(int)\n",
    "\n",
    "        #Player usage data\n",
    "        p_usage = pd.read_csv(f'Player Usage/Player Usage {con} {year}.csv')\n",
    "        p_usage = p_usage.rename(columns = {'Name':'Player', 'Id': 'PlayerId'}).sort_values(by = 'Player').reset_index(drop = True)\n",
    "\n",
    "        #Merge Player Stats and Player Usage\n",
    "        merged = p_usage.merge(p_stats_season, on = 'PlayerId', how = 'outer')\n",
    "        merged['Season'] = merged['Season'].apply(lambda x: 2023)\n",
    "        merged['Conference'] = merged['Conference'].apply(lambda x: 'Big Ten')\n",
    "\n",
    "\n",
    "        #2023 ALL CFB Player Basic Info\n",
    "        p_info = pd.read_csv(f'Player Basic Info/{year} Players Basic Info.csv')\n",
    "        p_info['Player'] = p_info['First Name'] + ' '+ p_info['Last Name']\n",
    "        p_info.rename(columns = {'Id': 'PlayerId'}, inplace=True)\n",
    "        p_info.drop(columns = ['First Name', 'Last Name'], inplace = True)\n",
    "        p_info.sort_values(by = 'Player', inplace = True)\n",
    "        p_info.dropna(inplace=True)\n",
    "\n",
    "        #Team Records\n",
    "        t_records = pd.read_csv(f'Team Records/Team Records {con} {year}.csv')\n",
    "        t_records.drop(columns=['Year', 'Conference'], inplace = True)\n",
    "\n",
    "        #Team Basic Stats\n",
    "        t_b_stats = pd.read_csv(f'Team Stats/Team Basic Stats {con} {year}.csv')\n",
    "        t_b_stats = t_b_stats[['Team', 'StatName', 'StatValue']].groupby(['Team', 'StatName']).sum().unstack()\n",
    "        t_b_stats.columns = t_b_stats.columns.droplevel(0)\n",
    "        t_b_stats.reset_index(inplace = True)\n",
    "        t_b_stats = t_b_stats.rename_axis(None, axis=1)\n",
    "        t_b_stats = t_b_stats.add_prefix('Team ')\n",
    "        t_b_stats.rename(columns={'Team Team': 'Team'},  inplace=True)\n",
    "\n",
    "        #Merge to fill in missing player info\n",
    "        merged2 = merged.merge(p_info, on = 'PlayerId', how = 'left', suffixes=[None, '_y'])\n",
    "        merged2['Position'] = merged2['Position'].combine_first(merged2['Position_y'])\n",
    "        merged2['Team'] = merged2['Team'].combine_first(merged2['Team_y'])\n",
    "        merged2['Player'] = merged2['Player'].combine_first(merged2['Player_y'])\n",
    "        merged2.drop(columns=['Team_y', 'Position_y', 'Player_y'], inplace= True)\n",
    "        merged2.sort_values(by = 'PlayerId')\n",
    "        merged2.dropna(subset = ['Player'], inplace=True)\n",
    "\n",
    "        #Merge Team Record Info\n",
    "        merged3 = merged2.merge(t_records, on = 'Team')\n",
    "\n",
    "        #Merge team basic stats\n",
    "        merged4 = merged3.merge(t_b_stats, on = 'Team')\n",
    "\n",
    "        #Load transfer data \n",
    "        transfer = pd.read_csv(f'Transfer Data/{year+1} Transfer.csv')\n",
    "        transfer['Player'] = transfer['FirstName'] + ' ' + transfer['LastName']\n",
    "        transfer.rename(columns = {'Origin': 'Team'}, inplace = True)\n",
    "        transfer = transfer[['Player','Team', 'Position', 'Stars']]\n",
    "        transfer = transfer.assign(Transfer_Portal ='Yes')\n",
    "\n",
    "        #Merge Data with Transfer Data \n",
    "        final_merged = merged4.merge(transfer, on = ['Player', 'Team', 'Position'], how = 'left')\n",
    "        final_merged['Transfer_Portal'] = final_merged['Transfer_Portal'].fillna('No')\n",
    "\n",
    "        final_merged.to_csv(f'Merged Datasets Con Year/{con} {year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for con in conferences:\n",
    "    #take in each year\n",
    "    set1 = pd.read_csv(f'Merged Datasets Con Year/{con} 2020.csv')\n",
    "    set2 = pd.read_csv(f'Merged Datasets Con Year/{con} 2021.csv')\n",
    "    set3 = pd.read_csv(f'Merged Datasets Con Year/{con} 2022.csv')\n",
    "    set4 = pd.read_csv(f'Merged Datasets Con Year/{con} 2023.csv')\n",
    "\n",
    "    #merge each year\n",
    "    merged = pd.concat([set1, set2, set3, set4])\n",
    "\n",
    "    #export to new single conference dataset\n",
    "    merged.to_csv(f'Merged Datasets Con/{con}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.read_csv(f'Merged Datasets Con/ACC.csv')\n",
    "big10 = pd.read_csv(f'Merged Datasets Con/Big10.csv')\n",
    "big12 = pd.read_csv(f'Merged Datasets Con/Big12.csv')\n",
    "sec = pd.read_csv(f'Merged Datasets Con/SEC.csv')\n",
    "pac12 = pd.read_csv(f'Merged Datasets Con/PAC12.csv')\n",
    "\n",
    "final_concat = pd.concat([acc, big10, big12, sec, pac12])\n",
    "\n",
    "final_concat = final_concat.drop(columns=['Unnamed: 0.1','Unnamed: 0'])\n",
    "\n",
    "#There was a mishap somewhere in the data downloading, and I need to define the columns we're going to include\n",
    "cols = ['Season', 'PlayerId', 'Player', 'Position', 'Team', 'Conference',\n",
    "       'Usage Overall', 'Usage Pass', 'Usage Rush', 'Usage FirstDown',\n",
    "       'Usage SecondDown', 'Usage ThirdDown', 'Usage StandardDowns',\n",
    "       'Usage PassingDowns', 'ATT', 'AVG', 'CAR', 'COMPLETIONS', 'FGA', 'FGM',\n",
    "       'FUM', 'INT', 'In 20', 'LONG', 'LOST', 'NO', 'PCT', 'PD', 'PTS',\n",
    "       'QB HUR', 'REC', 'SACKS', 'SOLO', 'TB', 'TD', 'TFL', 'TOT', 'XPA',\n",
    "       'XPM', 'YDS', 'YPA', 'YPC', 'YPP', 'YPR', 'Division', 'ExpectedWins',\n",
    "       'Total Games', 'Total Wins', 'Total Losses', 'Total Ties',\n",
    "       'ConferenceGames Games', 'ConferenceGames Wins',\n",
    "       'ConferenceGames Losses', 'ConferenceGames Ties', 'HomeGames Games',\n",
    "       'HomeGames Wins', 'HomeGames Losses', 'HomeGames Ties',\n",
    "       'AwayGames Games', 'AwayGames Wins', 'AwayGames Losses',\n",
    "       'AwayGames Ties', 'Team firstDowns', 'Team fourthDownConversions',\n",
    "       'Team fourthDowns', 'Team fumblesLost', 'Team fumblesRecovered',\n",
    "       'Team games', 'Team interceptionTDs', 'Team interceptionYards',\n",
    "       'Team interceptions', 'Team kickReturnTDs', 'Team kickReturnYards',\n",
    "       'Team kickReturns', 'Team netPassingYards', 'Team passAttempts',\n",
    "       'Team passCompletions', 'Team passesIntercepted', 'Team passingTDs',\n",
    "       'Team penalties', 'Team penaltyYards', 'Team possessionTime',\n",
    "       'Team puntReturnTDs', 'Team puntReturnYards', 'Team puntReturns',\n",
    "       'Team rushingAttempts', 'Team rushingTDs', 'Team rushingYards',\n",
    "       'Team sacks', 'Team tacklesForLoss', 'Team thirdDownConversions',\n",
    "       'Team thirdDowns', 'Team totalYards', 'Team turnovers', 'Stars',\n",
    "       'Transfer_Portal']\n",
    "\n",
    "final_concat = final_concat[cols]\n",
    "\n",
    "final_concat.to_csv('Final Dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>PlayerId</th>\n",
       "      <th>Player</th>\n",
       "      <th>Position</th>\n",
       "      <th>Team</th>\n",
       "      <th>Conference</th>\n",
       "      <th>Usage Overall</th>\n",
       "      <th>Usage Pass</th>\n",
       "      <th>Usage Rush</th>\n",
       "      <th>Usage FirstDown</th>\n",
       "      <th>...</th>\n",
       "      <th>Team rushingTDs</th>\n",
       "      <th>Team rushingYards</th>\n",
       "      <th>Team sacks</th>\n",
       "      <th>Team tacklesForLoss</th>\n",
       "      <th>Team thirdDownConversions</th>\n",
       "      <th>Team thirdDowns</th>\n",
       "      <th>Team totalYards</th>\n",
       "      <th>Team turnovers</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Transfer_Portal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>548077</td>\n",
       "      <td>Ryan Smith</td>\n",
       "      <td>LB</td>\n",
       "      <td>Duke</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1724</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>168</td>\n",
       "      <td>4165</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>3121655</td>\n",
       "      <td>Justus Reed</td>\n",
       "      <td>DL</td>\n",
       "      <td>Virginia Tech</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>2648</td>\n",
       "      <td>36</td>\n",
       "      <td>75</td>\n",
       "      <td>51</td>\n",
       "      <td>133</td>\n",
       "      <td>4860</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>3858274</td>\n",
       "      <td>Luc Bequette</td>\n",
       "      <td>DL</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1119</td>\n",
       "      <td>24</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "      <td>147</td>\n",
       "      <td>4245</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>3895797</td>\n",
       "      <td>Tre Tipton</td>\n",
       "      <td>WR</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1343</td>\n",
       "      <td>45</td>\n",
       "      <td>110</td>\n",
       "      <td>63</td>\n",
       "      <td>173</td>\n",
       "      <td>4200</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>3914537</td>\n",
       "      <td>Miles Fox</td>\n",
       "      <td>DL</td>\n",
       "      <td>Wake Forest</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>1491</td>\n",
       "      <td>16</td>\n",
       "      <td>68</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "      <td>4024</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12851</th>\n",
       "      <td>2023</td>\n",
       "      <td>5159802</td>\n",
       "      <td>Dallen Bentley</td>\n",
       "      <td>TE</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>2373</td>\n",
       "      <td>36</td>\n",
       "      <td>75</td>\n",
       "      <td>81</td>\n",
       "      <td>196</td>\n",
       "      <td>4529</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>2023</td>\n",
       "      <td>5159817</td>\n",
       "      <td>Joseph McGinnis II</td>\n",
       "      <td>DB</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1334</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>53</td>\n",
       "      <td>173</td>\n",
       "      <td>3858</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12853</th>\n",
       "      <td>2023</td>\n",
       "      <td>5161140</td>\n",
       "      <td>Ryan McCulloch</td>\n",
       "      <td>LB</td>\n",
       "      <td>California</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2250</td>\n",
       "      <td>25</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>191</td>\n",
       "      <td>5086</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854</th>\n",
       "      <td>2023</td>\n",
       "      <td>5161141</td>\n",
       "      <td>Mateen Bhaghani</td>\n",
       "      <td>PK</td>\n",
       "      <td>California</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2250</td>\n",
       "      <td>25</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>191</td>\n",
       "      <td>5086</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12855</th>\n",
       "      <td>2023</td>\n",
       "      <td>5161147</td>\n",
       "      <td>Marquis Montgomery</td>\n",
       "      <td>WR</td>\n",
       "      <td>California</td>\n",
       "      <td>Big Ten</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2250</td>\n",
       "      <td>25</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>191</td>\n",
       "      <td>5086</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12856 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Season  PlayerId              Player Position            Team  \\\n",
       "0        2023    548077          Ryan Smith       LB            Duke   \n",
       "1        2023   3121655         Justus Reed       DL   Virginia Tech   \n",
       "2        2023   3858274        Luc Bequette       DL  Boston College   \n",
       "3        2023   3895797          Tre Tipton       WR      Pittsburgh   \n",
       "4        2023   3914537           Miles Fox       DL     Wake Forest   \n",
       "...       ...       ...                 ...      ...             ...   \n",
       "12851    2023   5159802      Dallen Bentley       TE            Utah   \n",
       "12852    2023   5159817  Joseph McGinnis II       DB   Arizona State   \n",
       "12853    2023   5161140      Ryan McCulloch       LB      California   \n",
       "12854    2023   5161141     Mateen Bhaghani       PK      California   \n",
       "12855    2023   5161147  Marquis Montgomery       WR      California   \n",
       "\n",
       "      Conference  Usage Overall  Usage Pass  Usage Rush  Usage FirstDown  ...  \\\n",
       "0        Big Ten            NaN         NaN         NaN              NaN  ...   \n",
       "1        Big Ten            NaN         NaN         NaN              NaN  ...   \n",
       "2        Big Ten            NaN         NaN         NaN              NaN  ...   \n",
       "3        Big Ten         0.0186      0.0343         0.0           0.0202  ...   \n",
       "4        Big Ten            NaN         NaN         NaN              NaN  ...   \n",
       "...          ...            ...         ...         ...              ...  ...   \n",
       "12851    Big Ten         0.0011      0.0029         0.0           0.0000  ...   \n",
       "12852    Big Ten            NaN         NaN         NaN              NaN  ...   \n",
       "12853    Big Ten            NaN         NaN         NaN              NaN  ...   \n",
       "12854    Big Ten            NaN         NaN         NaN              NaN  ...   \n",
       "12855    Big Ten         0.0011      0.0023         0.0           0.0025  ...   \n",
       "\n",
       "       Team rushingTDs  Team rushingYards  Team sacks  Team tacklesForLoss  \\\n",
       "0                   19               1724          31                   67   \n",
       "1                   27               2648          36                   75   \n",
       "2                   11               1119          24                   52   \n",
       "3                   20               1343          45                  110   \n",
       "4                   22               1491          16                   68   \n",
       "...                ...                ...         ...                  ...   \n",
       "12851               19               2373          36                   75   \n",
       "12852               17               1334          26                   65   \n",
       "12853               26               2250          25                   58   \n",
       "12854               26               2250          25                   58   \n",
       "12855               26               2250          25                   58   \n",
       "\n",
       "       Team thirdDownConversions  Team thirdDowns  Team totalYards  \\\n",
       "0                             65              168             4165   \n",
       "1                             51              133             4860   \n",
       "2                             65              147             4245   \n",
       "3                             63              173             4200   \n",
       "4                             56              139             4024   \n",
       "...                          ...              ...              ...   \n",
       "12851                         81              196             4529   \n",
       "12852                         53              173             3858   \n",
       "12853                         74              191             5086   \n",
       "12854                         74              191             5086   \n",
       "12855                         74              191             5086   \n",
       "\n",
       "       Team turnovers  Stars  Transfer_Portal  \n",
       "0                  39    NaN               No  \n",
       "1                  14    NaN               No  \n",
       "2                  14    3.0              Yes  \n",
       "3                  16    NaN               No  \n",
       "4                   7    NaN               No  \n",
       "...               ...    ...              ...  \n",
       "12851              13    NaN               No  \n",
       "12852              20    NaN               No  \n",
       "12853              28    NaN               No  \n",
       "12854              28    NaN               No  \n",
       "12855              28    NaN               No  \n",
       "\n",
       "[12856 rows x 96 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Final Dataset.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
