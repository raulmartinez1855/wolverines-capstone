{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from classifiers.clf_utils import grid_cv_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset and Coaching Data\n",
    "data = pd.read_csv('Data/Final Dataset.csv')\n",
    "\n",
    "coaching_data = pd.read_csv('Data/Coaching Data.csv', skiprows = [0,1], skipfooter = 202)\n",
    "coaching_data = coaching_data.rename(columns = {'FBS Team': 'Team'})\n",
    "coaching_data = coaching_data[['Team','2019','2020','2021','2022','2023','2024']]\n",
    "coaching_data = coaching_data.melt(id_vars='Team', var_name = 'Season', value_name = 'Coach')\n",
    "coaching_data['Season'] = coaching_data['Season'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Coaching Change Function to Add Coaching Change Column to Data\n",
    "def coach_change(row, data):\n",
    "\n",
    "    team = str(row.Team)\n",
    "    season = int(row.Season)\n",
    "\n",
    "    try:\n",
    "    \n",
    "        curr_coach = data[(data['Team'] == team) & (data['Season'] == season)]['Coach']\n",
    "        curr_coach = curr_coach[curr_coach.index[0]]\n",
    "        next_coach = data[(data['Team'] == team) & (data['Season'] == season + 1)]['Coach']\n",
    "        next_coach = next_coach[next_coach.index[0]]\n",
    "\n",
    "        if curr_coach != next_coach:\n",
    "            return 'Yes'\n",
    "        return 'No'\n",
    "        \n",
    "    \n",
    "    except:\n",
    "        return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add coaching change info to data\n",
    "data['Coach Change'] = data.apply(lambda x: coach_change(x, coaching_data), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RB', 'WR', 'QB', 'TE', 'LB', 'DB', 'OL', 'DL', 'CB', 'S', 'PK',\n",
       "       'LS', 'P', 'DT', 'DE', 'FB', 'C', 'OT', 'G', 'NT', 'ATH', 'OLB',\n",
       "       '?'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = data.Position.unique()\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add recruiting info\n",
    "for i,year in enumerate(['2015','2016','2017','2018', '2019','2020', '2021', '2022', '2023']):\n",
    "    file = pd.read_csv('Data/Player Recruit Ranking/' + year + '.csv')\n",
    "    file.rename(columns = {'AthleteId': 'PlayerId', 'Year': 'Class of'}, inplace = True)\n",
    "    #file.drop(columns = ['Year', 'Rating', 'Ranking'], inplace = True)\n",
    "    #file.drop(columns = ['Year'], inplace = True)\n",
    "    data = data.merge(file, on = 'PlayerId', how = 'left', suffixes = [None, '_' + str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Columns\n",
    "for i in range(0,9):\n",
    "    data['Stars'] = data['Stars'].combine_first(data['Stars_' + str(i)])\n",
    "    data.drop(columns = ['Stars_' + str(i)], inplace = True)\n",
    "for i in range(1,9):\n",
    "    data['Rating'] = data['Rating'].combine_first(data['Rating_' + str(i)])\n",
    "    data['Ranking'] = data['Ranking'].combine_first(data['Ranking_' + str(i)])\n",
    "    data['Class of'] = data['Class of'].combine_first(data['Class of_' + str(i)])\n",
    "    data.drop(columns = ['Rating_' + str(i)], inplace = True)\n",
    "    data.drop(columns = ['Ranking_' + str(i)], inplace = True)\n",
    "    data.drop(columns = ['Class of_' + str(i)], inplace = True)\n",
    "\n",
    "data['Yr'] = data['Season'] - data['Class of'] + 1\n",
    "data.drop(columns = ['Class of'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine WR and TE into one position group since we don't have access to stats that would differentiate the two positions\n",
    "position_groups = {'OL':['OL', 'NT', 'OT', 'G', 'C','FB'],\n",
    "                   'QB':['QB'],\n",
    "                   'RB':['RB'],\n",
    "                   'WR':['WR', 'TE'],\n",
    "                   'DL':['DT', 'DE', 'DL'],\n",
    "                   'DB':['DB', 'CB', 'S'],\n",
    "                   'LB':['LB'],\n",
    "                   'ST':['LS', 'P', 'PK']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Data into Position Groups\n",
    "data_sets = {}\n",
    "for key in position_groups.keys():\n",
    "    data_sets[key] = data.copy()[data.copy()['Position'].isin(position_groups[key])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with WR and TE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr = data_sets['WR'].copy().drop(columns = ['PositionId', 'ConferenceId', 'TeamId'])\n",
    "wr['Stars'] = wr['Stars'].fillna(0)\n",
    "wr['Yr'] = wr['Yr'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engineer PCT Features\n",
    "wr['Pct_Team_Pass_Yds'] = wr['YDS']/wr['Team netPassingYards']\n",
    "wr['Pct_Team_Pass_TDs'] = wr['TD']/wr['Team passingTDs']\n",
    "wr['Pct_Team_Receptions'] = wr['REC']/wr['Team passCompletions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Improve Function\n",
    "def improve(row, column, data):\n",
    "    try: \n",
    "        id = int(row['PlayerId'])\n",
    "        season = int(row['Season'])\n",
    "        column = column\n",
    "        imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
    "\n",
    "        if imp:\n",
    "            return 1 \n",
    "        return -1\n",
    "    except:\n",
    "        return 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "C:\\Users\\Killen\\AppData\\Local\\Temp\\ipykernel_2964\\387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n"
     ]
    }
   ],
   "source": [
    "#Engineer Improve Features\n",
    "feats_to_improve = ['Usage Overall', 'Usage Pass', 'Usage Rush', 'Usage FirstDown','Usage SecondDown', 'Usage ThirdDown', 'Usage StandardDowns',\n",
    "       'Usage PassingDowns','REC', 'AVG','CAR','TD','YDS', 'YPR','Pct_Team_Pass_Yds',  'Pct_Team_Pass_TDs',\n",
    "       'Pct_Team_Receptions']\n",
    "\n",
    "for feat in feats_to_improve:\n",
    "    wr[feat+'_improve'] = wr.apply(lambda x: improve(x, feat, wr), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compare player stats with players of same year and star ranking\n",
    "def compare(row, column, data):\n",
    "    star = int(row['Stars'])\n",
    "    year = int(row['Yr'])\n",
    "    stat = column\n",
    "    pos = str(row['Position'])\n",
    "    id = int(row['PlayerId'])\n",
    "    season = int(row['Season'])\n",
    "\n",
    "    mean = data[(data['Stars'] == star) & (data['Yr'] == year) & (data['Position'] == pos)][stat].mean()\n",
    "    p_stat = data[(data['PlayerId'] == id)&(data['Season'] == season)][stat]\n",
    "    p_stat = p_stat[p_stat.index[0]]\n",
    "\n",
    "    if int(p_stat>mean):\n",
    "        return 1\n",
    "    elif int(p_stat<mean):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_compare = ['Usage Overall', 'Usage Pass', 'Usage Rush', 'Usage FirstDown','Usage SecondDown', 'Usage ThirdDown', 'Usage StandardDowns',\n",
    "       'Usage PassingDowns','REC', 'AVG','CAR','TD','YDS', 'YPR','Pct_Team_Pass_Yds',  'Pct_Team_Pass_TDs',\n",
    "       'Pct_Team_Receptions']\n",
    "for feat in feats_to_compare:\n",
    "    wr[feat + '_compare'] = wr.apply(lambda x: compare(x, feat, wr), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify Relevant Columns\n",
    "#No team stats added as of right now\n",
    "rel_feats = ['Usage Overall', 'Usage Pass', 'Usage Rush', 'Usage FirstDown','Usage SecondDown', 'Usage ThirdDown', 'Usage StandardDowns',\n",
    "             'Usage PassingDowns','REC', 'AVG','CAR','TD','YDS', 'YPR','Pct_Team_Pass_Yds',  'Pct_Team_Pass_TDs',\n",
    "             'Pct_Team_Receptions','Usage Overall_improve',\n",
    "             'Usage Pass_improve', 'Usage Rush_improve', 'Usage FirstDown_improve',\n",
    "             'Usage SecondDown_improve', 'Usage ThirdDown_improve',\n",
    "             'Usage StandardDowns_improve', 'Usage PassingDowns_improve',\n",
    "             'REC_improve', 'AVG_improve',\n",
    "             'CAR_improve', 'TD_improve', 'YDS_improve', 'YPR_improve',\n",
    "             'Pct_Team_Pass_Yds_improve', 'Pct_Team_Pass_TDs_improve',\n",
    "             'Pct_Team_Receptions_improve','Usage Overall_compare',\n",
    "             'Usage Pass_compare', 'Usage Rush_compare', 'Usage FirstDown_compare',\n",
    "             'Usage SecondDown_compare', 'Usage ThirdDown_compare',\n",
    "             'Usage StandardDowns_compare', 'Usage PassingDowns_compare',\n",
    "             'REC_compare', 'AVG_compare', 'CAR_compare', 'TD_compare',\n",
    "             'YDS_compare', 'YPR_compare', 'Pct_Team_Pass_Yds_compare',\n",
    "             'Pct_Team_Pass_TDs_compare', 'Pct_Team_Receptions_compare','Position','Yr','Stars', 'Coach Change', 'Ranking', 'Rating', 'Transfer_Portal']\n",
    "\n",
    "\n",
    "#Get rid of 2019, narrow down to relevant features\n",
    "wr = wr[wr['Season'] != 2019]\n",
    "wr = wr[rel_feats]\n",
    "#Encode Label Columns\n",
    "wr['Transfer_Portal'] = np.where(wr['Transfer_Portal'].values == 'Yes', 1, 0)\n",
    "\n",
    "#Convert Yr and Stars to Categorical Variables\n",
    "wr['Yr'] = wr['Yr'].astype('str')\n",
    "wr['Stars'] = wr['Stars'].astype('str')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Training and Testing Data\n",
    "X = wr.drop(columns=['Transfer_Portal'])\n",
    "y = wr['Transfer_Portal']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42, stratify=y)\n",
    "\n",
    "#Specify the Numerical Features and Categorical Features\n",
    "categorical = ['Usage Overall_improve',\n",
    "             'Usage Pass_improve', 'Usage Rush_improve', 'Usage FirstDown_improve',\n",
    "             'Usage SecondDown_improve', 'Usage ThirdDown_improve',\n",
    "             'Usage StandardDowns_improve', 'Usage PassingDowns_improve',\n",
    "             'REC_improve', 'AVG_improve',\n",
    "             'CAR_improve', 'TD_improve', 'YDS_improve', 'YPR_improve',\n",
    "             'Pct_Team_Pass_Yds_improve', 'Pct_Team_Pass_TDs_improve',\n",
    "             'Pct_Team_Receptions_improve','Position','Yr','Stars', 'Coach Change']\n",
    "\n",
    "numerical = [feat for feat in X.columns if feat not in categorical]\n",
    "\n",
    "#Pipeline to SimpleImpute and OneHot Encode Categorical Features (Training data only)\n",
    "impute_encode = Pipeline([('impute',SimpleImputer(strategy='constant',fill_value='N/A')), ('encode',OneHotEncoder(handle_unknown='ignore'))])\n",
    "column_transform = ColumnTransformer([('cat_encode', impute_encode, categorical), ('numerical_pass', SimpleImputer(strategy='constant',fill_value=0),numerical)])\n",
    "\n",
    "X_train = column_transform.fit_transform(X_train)\n",
    "col_trans = column_transform\n",
    "\n",
    "#Fit Pipeline ColumnTransformer to testing features\n",
    "X_test = column_transform.transform(X_test)\n",
    "\n",
    "#SMOTE Balancing of Training Data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores:\n",
      "0.6952398711706969\n",
      "0.7289322756817179\n",
      "0.7176628173737742\n",
      " \n",
      "Precision Scores:\n",
      "0.6952398711706969\n",
      "0.7012307621496914\n",
      "0.8737685985973066\n",
      " \n",
      "Recall Scores:\n",
      "0.6265871349006465\n",
      "0.7847626069379262\n",
      "0.6413305367504092\n"
     ]
    }
   ],
   "source": [
    "#CV Models w/ Training Data\n",
    "cv = KFold(n_splits = 5)\n",
    "\n",
    "def classifiers():\n",
    "    gb_clf = make_pipeline(StandardScaler(with_mean=False), GradientBoostingClassifier(random_state=42))\n",
    "    SVM_clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto'))\n",
    "    forest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    gb_f1 = cross_val_score(gb_clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    SVM_f1 = cross_val_score(SVM_clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    forest_f1 = cross_val_score(forest_clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "    gb_pre = cross_val_score(gb_clf, X_train, y_train, cv=cv, scoring='precision')\n",
    "    SVM_pre = cross_val_score(SVM_clf, X_train, y_train, cv=cv, scoring='precision')\n",
    "    forest_pre = cross_val_score(forest_clf, X_train, y_train, cv=cv, scoring='precision')\n",
    "\n",
    "    gb_re = cross_val_score(gb_clf, X_train, y_train, cv=cv, scoring='recall')\n",
    "    SVM_re = cross_val_score(SVM_clf, X_train, y_train, cv=cv, scoring='recall')\n",
    "    forest_re = cross_val_score(forest_clf, X_train, y_train, cv=cv, scoring='recall')\n",
    "\n",
    "    print('F1 Scores:')\n",
    "    print(gb_f1.mean())\n",
    "    print(SVM_f1.mean())\n",
    "    print(forest_f1.mean())\n",
    "    print(' ')\n",
    "    print('Precision Scores:')\n",
    "    print(gb_f1.mean())\n",
    "    print(SVM_pre.mean())\n",
    "    print(forest_pre.mean())\n",
    "    print(' ')\n",
    "    print('Recall Scores:')\n",
    "    print(gb_re.mean())\n",
    "    print(SVM_re.mean())\n",
    "    print(forest_re.mean())\n",
    "\n",
    "classifiers()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummmyClassifier Metrics\n",
      "-----------------------------------\n",
      "F1 Score:  0.1941747572815534\n",
      "Precision Score:  0.1282051282051282\n",
      "Recall Score:  0.4\n",
      "Accuracy:  0.49544072948328266\n"
     ]
    }
   ],
   "source": [
    "#Dummy Classifier:\n",
    "\n",
    "dummy = make_pipeline(StandardScaler(), DummyClassifier(random_state=42, strategy='stratified'))\n",
    "\n",
    "dummy.fit(X_train, y_train)\n",
    "preds = dummy.predict(X_test)\n",
    "\n",
    "\n",
    "print('DummmyClassifier Metrics')\n",
    "print('-----------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base GradientBoostingClassifier Metrics\n",
      "---------------------------------------\n",
      "F1 Score:  0.4057971014492754\n",
      "Precision Score:  0.7368421052631579\n",
      "Recall Score:  0.28\n",
      "Accuracy:  0.8753799392097265\n"
     ]
    }
   ],
   "source": [
    "#Evaluate trained model on test data\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),GradientBoostingClassifier(random_state=42))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print('Base GradientBoostingClassifier Metrics')\n",
    "print('---------------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base RandomForestClassifier Metrics\n",
      "-----------------------------------\n",
      "F1 Score:  0.28125\n",
      "Precision Score:  0.6428571428571429\n",
      "Recall Score:  0.18\n",
      "Accuracy:  0.8601823708206687\n"
     ]
    }
   ],
   "source": [
    "#Evaluate trained model on test data\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42, class_weight = 'balanced'))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print('Base RandomForestClassifier Metrics')\n",
    "print('-----------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds,))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base LogisticRegression Metrics\n",
      "-----------------------------------\n",
      "F1 Score:  0.3973509933774834\n",
      "Precision Score:  0.297029702970297\n",
      "Recall Score:  0.6\n",
      "Accuracy:  0.723404255319149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Killen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(),LogisticRegression(random_state=42, class_weight='balanced'))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print('Base LogisticRegression Metrics')\n",
    "print('-----------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning to Identify Best Performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GB Hyperparameter Tune\n",
    "RANDOM_STATE = 42\n",
    "gb_clf = grid_cv_model(\n",
    "     X=X_train,\n",
    "     y=y_train,\n",
    "     model= GradientBoostingClassifier(),\n",
    "     params={\n",
    "         \"random_state\": [RANDOM_STATE],\n",
    "         \"learning_rate\": [0.01, 0.015, 0.02,0.05, 0.075, 0.1],\n",
    "         \"n_estimators\": np.arange(1,100,1),\n",
    "         \"max_features\":['sqrt', 'log2', None]\n",
    "     },\n",
    "     cv=5,\n",
    "     scoring='recall'\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GradientBoostingClassifier Metrics\n",
      "---------------------------------------\n",
      "Best Model: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 GradientBoostingClassifier(learning_rate=0.075,\n",
      "                                            n_estimators=30,\n",
      "                                            random_state=42))])\n",
      "F1 Score:  0.5647058823529412\n",
      "Precision Score:  0.6857142857142857\n",
      "Recall Score:  0.48\n",
      "Accuracy:  0.8875379939209727\n"
     ]
    }
   ],
   "source": [
    "best_gb = gb_clf.best_estimator_\n",
    "preds =  best_gb.predict(X_test)\n",
    "\n",
    "print('Best GradientBoostingClassifier Metrics')\n",
    "print('---------------------------------------')\n",
    "print('Best Model:', best_gb)\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF Hyperparameter Tune\n",
    "RANDOM_STATE = 42\n",
    "rf_clf = grid_cv_model(\n",
    "     X=X_train,\n",
    "     y=y_train,\n",
    "     model= RandomForestClassifier(class_weight = 'balanced'),\n",
    "     params={\n",
    "         \"random_state\": [RANDOM_STATE],\n",
    "         \"n_estimators\": np.arange(1,100,1),\n",
    "         \"max_features\":['sqrt', 'log2', None], \n",
    "         \"criterion\": ['gini', 'entropy', 'log_loss']\n",
    "     },\n",
    "     cv=5,\n",
    "     scoring='recall'\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForestClassifier Metrics\n",
      "---------------------------------------\n",
      "Best Model: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(class_weight='balanced',\n",
      "                                        max_features=None, n_estimators=7,\n",
      "                                        random_state=42))])\n",
      "F1 Score:  0.36363636363636365\n",
      "Precision Score:  0.42105263157894735\n",
      "Recall Score:  0.32\n",
      "Accuracy:  0.8297872340425532\n"
     ]
    }
   ],
   "source": [
    "best_rf = rf_clf.best_estimator_\n",
    "preds =  best_rf.predict(X_test)\n",
    "\n",
    "print('Best RandomForestClassifier Metrics')\n",
    "print('---------------------------------------')\n",
    "print('Best Model:', best_rf)\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR Hyperparameter Tune\n",
    "RANDOM_STATE = 42\n",
    "lr_clf = grid_cv_model(\n",
    "     X=X_train,\n",
    "     y=y_train,\n",
    "     model= LogisticRegression(class_weight='balanced'),\n",
    "     params={\n",
    "         \"random_state\": [RANDOM_STATE],\n",
    "         \"penalty\": ['l2'],\n",
    "         \"solver\": ['lbfgs', 'liblinear'], \n",
    "         \"C\": [1, 5, 10, 100, 1000], \n",
    "         \"max_iter\": np.arange(10000, 11000, 100)\n",
    "     },\n",
    "     cv=5,\n",
    "     scoring='recall'\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LogisticRegression Metrics\n",
      "---------------------------------------\n",
      "Best Model: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 LogisticRegression(C=100, class_weight='balanced',\n",
      "                                    max_iter=10000, random_state=42,\n",
      "                                    solver='liblinear'))])\n",
      "F1 Score:  0.4025974025974026\n",
      "Precision Score:  0.2980769230769231\n",
      "Recall Score:  0.62\n",
      "Accuracy:  0.7203647416413373\n"
     ]
    }
   ],
   "source": [
    "best_lr = lr_clf.best_estimator_\n",
    "preds = best_lr.predict(X_test)\n",
    "\n",
    "print('Best LogisticRegression Metrics')\n",
    "print('---------------------------------------')\n",
    "print('Best Model:', best_lr)\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['column_transform_wr_te.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(best_gb, 'wr_te_classifier.joblib')\n",
    "dump(col_trans, \"column_transform_wr_te.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression probabilities of a player entering the transfer portal\n",
      "---------------------------------------\n",
      "Average probability of players who did enter:  0.6339667460869521\n",
      "Average probability of players who did NOT enter:  0.33100088898142066\n",
      " \n",
      "GB probabilities of a player entering the transfer portal\n",
      "---------------------------------------\n",
      "Average probability of players who did enter:  0.46958538005893974\n",
      "Average probability of players who did NOT enter:  0.2834777545874451\n"
     ]
    }
   ],
   "source": [
    "X_pos = wr[wr['Transfer_Portal'] == 1].drop(columns=['Transfer_Portal'])\n",
    "X_neg = wr[wr['Transfer_Portal'] == 0].drop(columns=['Transfer_Portal'])\n",
    "\n",
    "X_pos = column_transform.transform(X_pos)\n",
    "X_neg = column_transform.transform(X_neg)\n",
    "\n",
    "def average(nest_list):\n",
    "    probs = []\n",
    "    for i in nest_list:\n",
    "        probs.append(i[1])\n",
    "\n",
    "    return sum(probs)/len(nest_list)\n",
    "\n",
    "log_pos_proba = average(best_lr.predict_proba(X_pos))\n",
    "log_neg_proba = average(best_lr.predict_proba(X_neg))\n",
    "\n",
    "gb_pos_proba = average(best_gb.predict_proba(X_pos))\n",
    "gb_neg_proba = average(best_gb.predict_proba(X_neg))\n",
    "\n",
    "print('Logistic Regression probabilities of a player entering the transfer portal')\n",
    "print('---------------------------------------')\n",
    "print('Average probability of players who did enter: ', log_pos_proba)\n",
    "print('Average probability of players who did NOT enter: ', log_neg_proba)\n",
    "print(' ')\n",
    "print('GB probabilities of a player entering the transfer portal')\n",
    "print('---------------------------------------')\n",
    "print('Average probability of players who did enter: ', gb_pos_proba)\n",
    "print('Average probability of players who did NOT enter: ', gb_neg_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
