{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2019,2020,2021,2022,2023]\n",
    "conferences = ['ACC', 'Big10', 'Big12', 'SEC', 'PAC12']\n",
    "\n",
    "for year in years:\n",
    "    for con in conferences:\n",
    "\n",
    "        #Player Stats by Season\n",
    "        p_stats_season = pd.read_csv(f'Player Stats/Player Stats By Season {con} {year}.csv')\n",
    "        #Remove 'Team' Player\n",
    "        p_stats_season = p_stats_season[p_stats_season['Player'] != ' Team']\n",
    "\n",
    "        #Group Player Stats by PlayerId\n",
    "        p_stats_season = p_stats_season[['PlayerId', 'StatType', 'Stat']].groupby(['PlayerId', 'StatType']).sum().unstack()\n",
    "        p_stats_season.columns = p_stats_season.columns.droplevel(0)\n",
    "        p_stats_season.reset_index(inplace = True)\n",
    "        p_stats_season = p_stats_season.rename_axis(None, axis=1)\n",
    "        p_stats_season.index = p_stats_season.index.map(int)\n",
    "\n",
    "        #Player usage data\n",
    "        p_usage = pd.read_csv(f'Player Usage/Player Usage {con} {year}.csv')\n",
    "        p_usage = p_usage.rename(columns = {'Name':'Player', 'Id': 'PlayerId'}).sort_values(by = 'Player').reset_index(drop = True)\n",
    "\n",
    "        #Merge Player Stats and Player Usage\n",
    "        merged = p_usage.merge(p_stats_season, on = 'PlayerId', how = 'outer')\n",
    "        merged['Season'] = merged['Season'].apply(lambda x: year)\n",
    "        merged['Conference'] = merged['Conference'].apply(lambda x: con)\n",
    "\n",
    "\n",
    "        #2023 ALL CFB Player Basic Info\n",
    "        p_info = pd.read_csv(f'Player Basic Info/{year} Players Basic Info.csv')\n",
    "        p_info['Player'] = p_info['First Name'] + ' '+ p_info['Last Name']\n",
    "        p_info.rename(columns = {'Id': 'PlayerId'}, inplace=True)\n",
    "        p_info.drop(columns = ['First Name', 'Last Name'], inplace = True)\n",
    "        p_info.sort_values(by = 'Player', inplace = True)\n",
    "        p_info.dropna(inplace=True)\n",
    "\n",
    "        #Team Records\n",
    "        t_records = pd.read_csv(f'Team Records/Team Records {con} {year}.csv')\n",
    "        t_records.drop(columns=['Year', 'Conference'], inplace = True)\n",
    "\n",
    "        #Team Basic Stats\n",
    "        t_b_stats = pd.read_csv(f'Team Stats/Team Basic Stats {con} {year}.csv')\n",
    "        t_b_stats = t_b_stats[['Team', 'StatName', 'StatValue']].groupby(['Team', 'StatName']).sum().unstack()\n",
    "        t_b_stats.columns = t_b_stats.columns.droplevel(0)\n",
    "        t_b_stats.reset_index(inplace = True)\n",
    "        t_b_stats = t_b_stats.rename_axis(None, axis=1)\n",
    "        t_b_stats = t_b_stats.add_prefix('Team ')\n",
    "        t_b_stats.rename(columns={'Team Team': 'Team'},  inplace=True)\n",
    "\n",
    "        #Merge to fill in missing player info\n",
    "        merged2 = merged.merge(p_info, on = 'PlayerId', how = 'left', suffixes=[None, '_y'])\n",
    "        merged2['Position'] = merged2['Position'].combine_first(merged2['Position_y'])\n",
    "        merged2['Team'] = merged2['Team'].combine_first(merged2['Team_y'])\n",
    "        merged2['Player'] = merged2['Player'].combine_first(merged2['Player_y'])\n",
    "        merged2.drop(columns=['Team_y', 'Position_y', 'Player_y'], inplace= True)\n",
    "        merged2.sort_values(by = 'PlayerId')\n",
    "        merged2.dropna(subset = ['Player'], inplace=True)\n",
    "\n",
    "        #Merge Team Record Info\n",
    "        merged3 = merged2.merge(t_records, on = 'Team')\n",
    "\n",
    "        #Merge team basic stats\n",
    "        merged4 = merged3.merge(t_b_stats, on = 'Team')\n",
    "\n",
    "        #Load transfer data \n",
    "        transfer = pd.read_csv(f'Transfer Data/{year+1} Transfer.csv')\n",
    "        transfer['Player'] = transfer['FirstName'] + ' ' + transfer['LastName']\n",
    "        transfer.rename(columns = {'Origin': 'Team'}, inplace = True)\n",
    "        transfer = transfer[['Player','Team', 'Position', 'Stars']]\n",
    "        transfer = transfer.assign(Transfer_Portal ='Yes')\n",
    "\n",
    "        #Merge Data with Transfer Data \n",
    "        final_merged = merged4.merge(transfer, on = ['Player', 'Team', 'Position'], how = 'left')\n",
    "        final_merged['Transfer_Portal'] = final_merged['Transfer_Portal'].fillna('No')\n",
    "\n",
    "        final_merged.to_csv(f'Merged Datasets Con Year/{con} {year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for con in conferences:\n",
    "    #take in each year\n",
    "    set0 = pd.read_csv(f'Merged Datasets Con Year/{con} 2019.csv')\n",
    "    set1 = pd.read_csv(f'Merged Datasets Con Year/{con} 2020.csv')\n",
    "    set2 = pd.read_csv(f'Merged Datasets Con Year/{con} 2021.csv')\n",
    "    set3 = pd.read_csv(f'Merged Datasets Con Year/{con} 2022.csv')\n",
    "    set4 = pd.read_csv(f'Merged Datasets Con Year/{con} 2023.csv')\n",
    "\n",
    "    #merge each year\n",
    "    merged = pd.concat([set0,set1, set2, set3, set4])\n",
    "\n",
    "    #export to new single conference dataset\n",
    "    merged.to_csv(f'Merged Datasets Con/{con}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.read_csv(f'Merged Datasets Con/ACC.csv')\n",
    "big10 = pd.read_csv(f'Merged Datasets Con/Big10.csv')\n",
    "big12 = pd.read_csv(f'Merged Datasets Con/Big12.csv')\n",
    "sec = pd.read_csv(f'Merged Datasets Con/SEC.csv')\n",
    "pac12 = pd.read_csv(f'Merged Datasets Con/PAC12.csv')\n",
    "\n",
    "\n",
    "final_concat = pd.concat([acc, big10, big12, sec, pac12])\n",
    "\n",
    "final_concat = final_concat.drop(columns=['Unnamed: 0.1','Unnamed: 0'])\n",
    "\n",
    "#There was a mishap somewhere in the data downloading, and I need to define the columns we're going to include\n",
    "cols = ['Season', 'PlayerId', 'Player', 'Position', 'Team', 'Conference',\n",
    "       'Usage Overall', 'Usage Pass', 'Usage Rush', 'Usage FirstDown',\n",
    "       'Usage SecondDown', 'Usage ThirdDown', 'Usage StandardDowns',\n",
    "       'Usage PassingDowns', 'ATT', 'AVG', 'CAR', 'COMPLETIONS', 'FGA', 'FGM',\n",
    "       'FUM', 'INT', 'In 20', 'LONG', 'LOST', 'NO', 'PCT', 'PD', 'PTS',\n",
    "       'QB HUR', 'REC', 'SACKS', 'SOLO', 'TB', 'TD', 'TFL', 'TOT', 'XPA',\n",
    "       'XPM', 'YDS', 'YPA', 'YPC', 'YPP', 'YPR', 'Division', 'ExpectedWins',\n",
    "       'Total Games', 'Total Wins', 'Total Losses', 'Total Ties',\n",
    "       'ConferenceGames Games', 'ConferenceGames Wins',\n",
    "       'ConferenceGames Losses', 'ConferenceGames Ties', 'HomeGames Games',\n",
    "       'HomeGames Wins', 'HomeGames Losses', 'HomeGames Ties',\n",
    "       'AwayGames Games', 'AwayGames Wins', 'AwayGames Losses',\n",
    "       'AwayGames Ties', 'Team firstDowns', 'Team fourthDownConversions',\n",
    "       'Team fourthDowns', 'Team fumblesLost', 'Team fumblesRecovered',\n",
    "       'Team games', 'Team interceptionTDs', 'Team interceptionYards',\n",
    "       'Team interceptions', 'Team kickReturnTDs', 'Team kickReturnYards',\n",
    "       'Team kickReturns', 'Team netPassingYards', 'Team passAttempts',\n",
    "       'Team passCompletions', 'Team passesIntercepted', 'Team passingTDs',\n",
    "       'Team penalties', 'Team penaltyYards', 'Team possessionTime',\n",
    "       'Team puntReturnTDs', 'Team puntReturnYards', 'Team puntReturns',\n",
    "       'Team rushingAttempts', 'Team rushingTDs', 'Team rushingYards',\n",
    "       'Team sacks', 'Team tacklesForLoss', 'Team thirdDownConversions',\n",
    "       'Team thirdDowns', 'Team totalYards', 'Team turnovers', 'Stars',\n",
    "       'Transfer_Portal']\n",
    "\n",
    "final_concat = final_concat[cols]\n",
    "\n",
    "position_dict = {}\n",
    "team_dict = {}\n",
    "con_dict = {}\n",
    "\n",
    "for i,pos in enumerate(final_concat.Position.unique()):\n",
    "    position_dict[pos] = i\n",
    "\n",
    "for i,team in enumerate(final_concat.Team.unique()):\n",
    "    team_dict[team] = i\n",
    "\n",
    "for i,con in enumerate(final_concat.Conference.unique()):\n",
    "    con_dict[con] = i\n",
    "\n",
    "final_concat['PositionId'] = final_concat['Position'].map(position_dict)\n",
    "final_concat['TeamId'] = final_concat['Team'].map(team_dict)\n",
    "final_concat['ConferenceId'] = final_concat['Conference'].map(con_dict)\n",
    "\n",
    "final_concat.to_csv('Final Dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
