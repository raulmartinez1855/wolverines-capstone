{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from  clf_utils import grid_cv_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/736867005.py:2: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('Data/Final Dataset.csv')\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/736867005.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  coaching_data = pd.read_csv('Data/Coaching Data.csv', skiprows = [0,1], skipfooter = 202)\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset and Coaching Data\n",
    "data = pd.read_csv('../Data/Final Dataset.csv')\n",
    "\n",
    "coaching_data = pd.read_csv('../Data/Coaching Data.csv', skiprows = [0,1], skipfooter = 202)\n",
    "coaching_data = coaching_data.rename(columns = {'FBS Team': 'Team'})\n",
    "coaching_data = coaching_data[['Team','2019','2020','2021','2022','2023','2024']]\n",
    "coaching_data = coaching_data.melt(id_vars='Team', var_name = 'Season', value_name = 'Coach')\n",
    "coaching_data['Season'] = coaching_data['Season'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Coaching Change Function to Add Coaching Change Column to Data\n",
    "def coach_change(row, data):\n",
    "\n",
    "    team = str(row.Team)\n",
    "    season = int(row.Season)\n",
    "\n",
    "    try:\n",
    "    \n",
    "        curr_coach = data[(data['Team'] == team) & (data['Season'] == season)]['Coach']\n",
    "        curr_coach = curr_coach[curr_coach.index[0]]\n",
    "        next_coach = data[(data['Team'] == team) & (data['Season'] == season + 1)]['Coach']\n",
    "        next_coach = next_coach[next_coach.index[0]]\n",
    "\n",
    "        if curr_coach != next_coach:\n",
    "            return 'Yes'\n",
    "        return 'No'\n",
    "        \n",
    "    \n",
    "    except:\n",
    "        return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add coaching change info to data\n",
    "data['Coach Change'] = data.apply(lambda x: coach_change(x, coaching_data), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RB', 'WR', 'QB', 'TE', 'LB', 'DB', 'OL', 'DL', 'CB', 'S', 'PK',\n",
       "       'LS', 'P', 'DT', 'DE', 'FB', 'C', 'OT', 'G', 'NT', 'ATH', 'OLB',\n",
       "       '?'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = data.Position.unique()\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add recruiting info\n",
    "for i,year in enumerate(['2015','2016','2017','2018', '2019','2020', '2021', '2022', '2023']):\n",
    "    file = pd.read_csv('../Data/Player Recruit Ranking/' + year + '.csv')\n",
    "    file.rename(columns = {'AthleteId': 'PlayerId', 'Year': 'Class of'}, inplace = True)\n",
    "    #file.drop(columns = ['Year', 'Rating', 'Ranking'], inplace = True)\n",
    "    #file.drop(columns = ['Year'], inplace = True)\n",
    "    data = data.merge(file, on = 'PlayerId', how = 'left', suffixes = [None, '_' + str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Columns\n",
    "for i in range(0,9):\n",
    "    data['Stars'] = data['Stars'].combine_first(data['Stars_' + str(i)])\n",
    "    data.drop(columns = ['Stars_' + str(i)], inplace = True)\n",
    "for i in range(1,9):\n",
    "    data['Rating'] = data['Rating'].combine_first(data['Rating_' + str(i)])\n",
    "    data['Ranking'] = data['Ranking'].combine_first(data['Ranking_' + str(i)])\n",
    "    data['Class of'] = data['Class of'].combine_first(data['Class of_' + str(i)])\n",
    "    data.drop(columns = ['Rating_' + str(i)], inplace = True)\n",
    "    data.drop(columns = ['Ranking_' + str(i)], inplace = True)\n",
    "    data.drop(columns = ['Class of_' + str(i)], inplace = True)\n",
    "\n",
    "data['Yr'] = data['Season'] - data['Class of'] + 1\n",
    "data.drop(columns = ['Class of'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_groups = {'OL':['OL', 'NT', 'OT', 'G', 'C','FB'],\n",
    "                   'TE':['TE'],\n",
    "                   'QB':['QB'],\n",
    "                   'RB':['RB'],\n",
    "                   'WR':['WR'],\n",
    "                   'DL':['DT', 'DE', 'DL'],\n",
    "                   'DB':['DB', 'CB', 'S'],\n",
    "                   'LB':['LB'],\n",
    "                   'ST':['LS', 'P', 'PK']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Data into Position Groups\n",
    "data_sets = {}\n",
    "for key in position_groups.keys():\n",
    "    data_sets[key] = data.copy()[data.copy()['Position'].isin(position_groups[key])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with RB Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = data_sets['RB'].copy().drop(columns = ['PositionId', 'ConferenceId', 'TeamId'])\n",
    "#Fill NaN for Stars w/ Zero, since players can have Zero Star Rating and Yr w/ Zero for players w/o year information\n",
    "rb['Stars'] = rb['Stars'].fillna(0)\n",
    "rb['Yr'] = rb['Yr'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engineer PCT Features\n",
    "rb['Pct_Team_Rush_Yds'] = rb['YDS']/rb['Team rushingYards']\n",
    "rb['Pct_Team_Rush_Attempts'] = rb['CAR']/rb['Team rushingAttempts']\n",
    "rb['Pct_Team_Rush_TDs'] = rb['TD']/rb['Team rushingTDs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Improve Function\n",
    "def improve(row, column, data):\n",
    "    try: \n",
    "        id = int(row['PlayerId'])\n",
    "        season = int(row['Season'])\n",
    "        column = column\n",
    "        imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
    "\n",
    "        if imp:\n",
    "            return 1 \n",
    "        return -1\n",
    "    except:\n",
    "        return 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_30381/387796436.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n"
     ]
    }
   ],
   "source": [
    "#Engineer Improve Features\n",
    "feats_to_improve = ['Usage Overall', 'Usage Rush', 'Usage Pass','Usage PassingDowns', 'Usage StandardDowns', 'Usage FirstDown', 'Usage SecondDown', 'Usage ThirdDown', 'AVG', \n",
    "         'CAR', 'YPC', 'REC', 'YPR', 'Pct_Team_Rush_Yds', 'Pct_Team_Rush_Attempts', 'Pct_Team_Rush_TDs']\n",
    "\n",
    "for feat in feats_to_improve:\n",
    "    rb[feat+'_improve'] = rb.apply(lambda x: improve(x, feat, rb), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compare player stats with players of same year and star ranking\n",
    "def compare(row, column, data):\n",
    "    star = int(row['Stars'])\n",
    "    year = int(row['Yr'])\n",
    "    stat = column\n",
    "    pos = str(row['Position'])\n",
    "    id = int(row['PlayerId'])\n",
    "    season = int(row['Season'])\n",
    "\n",
    "    mean = data[(data['Stars'] == star) & (data['Yr'] == year) & (data['Position'] == pos)][stat].mean()\n",
    "    p_stat = data[(data['PlayerId'] == id)&(data['Season'] == season)][stat]\n",
    "    p_stat = p_stat[p_stat.index[0]]\n",
    "\n",
    "    if int(p_stat>mean):\n",
    "        return 1\n",
    "    elif int(p_stat<mean):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_compare = ['Usage Overall', 'Usage Rush', 'Usage Pass','Usage PassingDowns', 'Usage StandardDowns', 'Usage FirstDown', 'Usage SecondDown', 'Usage ThirdDown', 'AVG', \n",
    "         'CAR', 'YPC', 'REC', 'YPR', 'Pct_Team_Rush_Yds', 'Pct_Team_Rush_Attempts', 'Pct_Team_Rush_TDs']\n",
    "\n",
    "for feat in feats_to_compare:\n",
    "    rb[feat + '_compare'] = rb.apply(lambda x: compare(x, feat, rb), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify Relevant Columns\n",
    "rel_feats = ['Usage Overall', 'Usage Rush','Usage StandardDowns', 'Usage FirstDown', 'Usage SecondDown', 'Usage ThirdDown', 'AVG', \n",
    "             'CAR', 'YPC', 'REC', 'YPR', 'Pct_Team_Rush_Yds', 'Pct_Team_Rush_Attempts', 'Pct_Team_Rush_TDs',\n",
    "             'Usage Overall_improve', 'Usage Rush_improve', 'Usage Pass_improve',\n",
    "             'Usage PassingDowns_improve', 'Usage StandardDowns_improve',\n",
    "             'Usage FirstDown_improve', 'Usage SecondDown_improve',\n",
    "             'Usage ThirdDown_improve', 'AVG_improve', 'CAR_improve', 'YPC_improve',\n",
    "             'REC_improve', 'YPR_improve', 'Pct_Team_Rush_Yds_improve',\n",
    "             'Pct_Team_Rush_Attempts_improve', 'Pct_Team_Rush_TDs_improve','Usage Overall_compare', 'Usage Rush_compare', 'Usage Pass_compare',\n",
    "             'Usage PassingDowns_compare', 'Usage StandardDowns_compare',\n",
    "             'Usage FirstDown_compare', 'Usage SecondDown_compare',\n",
    "             'Usage ThirdDown_compare', 'AVG_compare', 'CAR_compare', 'YPC_compare',\n",
    "             'REC_compare', 'YPR_compare', 'Pct_Team_Rush_Yds_compare',\n",
    "             'Pct_Team_Rush_Attempts_compare', 'Pct_Team_Rush_TDs_compare',\n",
    "             'Position','Yr','Stars', 'Coach Change', 'Ranking', 'Rating', 'Transfer_Portal']\n",
    "\n",
    "#Get rid of 2019, narrow down to relevant features\n",
    "rb = rb[rb['Season'] != 2019]\n",
    "rb = rb[rel_feats]\n",
    "#Encode Label Column\n",
    "rb['Transfer_Portal'] = np.where(rb['Transfer_Portal'].values == 'Yes', 1, 0)\n",
    "\n",
    "#Convert Yr and Stars to Categorical Variables\n",
    "rb['Yr'] = rb['Yr'].astype('str')\n",
    "rb['Stars'] = rb['Stars'].astype('str')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Training and Testing Data\n",
    "X = rb.drop(columns=['Transfer_Portal'])\n",
    "y = rb['Transfer_Portal']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42, stratify=y)\n",
    "\n",
    "#Specify the Numerical Features and Categorical Features\n",
    "categorical = ['Yr', 'Stars','Position','Coach Change']\n",
    "\n",
    "numerical = [feat for feat in X.columns if feat not in categorical]\n",
    "\n",
    "#Pipeline to SimpleImpute and OneHot Encode Categorical Features (Training data only)\n",
    "impute_encode = Pipeline([('impute',SimpleImputer(strategy='constant',fill_value='N/A')), ('encode',OneHotEncoder(handle_unknown='infrequent_if_exist'))])\n",
    "column_transform = ColumnTransformer([('cat_encode', impute_encode, categorical), ('numerical_pass', SimpleImputer(strategy='constant',fill_value=0),numerical)])\n",
    "\n",
    "X_train = column_transform.fit_transform(X_train)\n",
    "\n",
    "#Fit Pipeline ColumnTransformer to testing features\n",
    "X_test = column_transform.transform(X_test)\n",
    "\n",
    "#SMOTE Balancing of Training Data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores:\n",
      "0.9137880583165862\n",
      "0.882125033677829\n",
      "0.9258144167801055\n",
      " \n",
      "Precision Scores:\n",
      "0.9137880583165862\n",
      "0.8768966690016928\n",
      "0.9565689439828187\n",
      " \n",
      "Recall Scores:\n",
      "0.8863992853051279\n",
      "0.8876522380343858\n",
      "0.8973049642861721\n"
     ]
    }
   ],
   "source": [
    "#CV Models w/ Training Data\n",
    "cv = KFold(n_splits = 5, shuffle=True, random_state=42)\n",
    "\n",
    "def classifiers():\n",
    "    gb_clf = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=42))\n",
    "    SVM_clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    forest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    gb_f1 = cross_val_score(gb_clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    SVM_f1 = cross_val_score(SVM_clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    forest_f1 = cross_val_score(forest_clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "    gb_pre = cross_val_score(gb_clf, X_train, y_train, cv=cv, scoring='precision')\n",
    "    SVM_pre = cross_val_score(SVM_clf, X_train, y_train, cv=cv, scoring='precision')\n",
    "    forest_pre = cross_val_score(forest_clf, X_train, y_train, cv=cv, scoring='precision')\n",
    "\n",
    "    gb_re = cross_val_score(gb_clf, X_train, y_train, cv=cv, scoring='recall')\n",
    "    SVM_re = cross_val_score(SVM_clf, X_train, y_train, cv=cv, scoring='recall')\n",
    "    forest_re = cross_val_score(forest_clf, X_train, y_train, cv=cv, scoring='recall')\n",
    "\n",
    "    print('F1 Scores:')\n",
    "    print(gb_f1.mean())\n",
    "    print(SVM_f1.mean())\n",
    "    print(forest_f1.mean())\n",
    "    print(' ')\n",
    "    print('Precision Scores:')\n",
    "    print(gb_f1.mean())\n",
    "    print(SVM_pre.mean())\n",
    "    print(forest_pre.mean())\n",
    "    print(' ')\n",
    "    print('Recall Scores:')\n",
    "    print(gb_re.mean())\n",
    "    print(SVM_re.mean())\n",
    "    print(forest_re.mean())\n",
    "\n",
    "classifiers()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Base Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummmyClassifier Metrics\n",
      "-----------------------------------\n",
      "F1 Score:  0.22680412371134023\n",
      "Precision Score:  0.14473684210526316\n",
      "Recall Score:  0.5238095238095238\n",
      "Accuracy:  0.4791666666666667\n"
     ]
    }
   ],
   "source": [
    "#Dummy Classifier:\n",
    "\n",
    "dummy = make_pipeline(StandardScaler(), DummyClassifier(random_state=42, strategy='stratified'))\n",
    "\n",
    "dummy.fit(X_train, y_train)\n",
    "preds = dummy.predict(X_test)\n",
    "\n",
    "\n",
    "print('DummmyClassifier Metrics')\n",
    "print('-----------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base GradientBoostingClassifier Metrics\n",
      "-----------------------------------\n",
      "F1 Score:  0.4848484848484849\n",
      "Precision Score:  0.6666666666666666\n",
      "Recall Score:  0.38095238095238093\n",
      "Accuracy:  0.8819444444444444\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=42))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print('Base GradientBoostingClassifier Metrics')\n",
    "print('-----------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base RandomForestClassifier Metrics\n",
      "-----------------------------------\n",
      "F1 Score:  0.35714285714285715\n",
      "Precision Score:  0.7142857142857143\n",
      "Recall Score:  0.23809523809523808\n",
      "Accuracy:  0.875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print('Base RandomForestClassifier Metrics')\n",
    "print('-----------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base LogisticRegression Metrics\n",
      "-----------------------------------\n",
      "F1 Score:  0.5\n",
      "Precision Score:  0.38461538461538464\n",
      "Recall Score:  0.7142857142857143\n",
      "Accuracy:  0.7916666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashdave/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(StandardScaler(),LogisticRegression(random_state=42, class_weight='balanced'))\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print('Base LogisticRegression Metrics')\n",
    "print('-----------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning to Identify Best Performing Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GB Hyperparameter Tune\n",
    "RANDOM_STATE = 42\n",
    "gb_clf = grid_cv_model(\n",
    "     X=X_train,\n",
    "     y=y_train,\n",
    "     model= GradientBoostingClassifier(),\n",
    "     params={\n",
    "         \"random_state\": [RANDOM_STATE],\n",
    "         \"learning_rate\": [0.01, 0.015, 0.02,0.05, 0.075, 0.1],\n",
    "         \"n_estimators\": np.arange(1,100,1),\n",
    "         \"max_features\":['sqrt', 'log2', None]\n",
    "     },\n",
    "     cv=5,\n",
    "     scoring='recall'\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GradientBoostingClassifier Metrics\n",
      "---------------------------------------\n",
      "Best Model: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 GradientBoostingClassifier(learning_rate=0.075,\n",
      "                                            n_estimators=26,\n",
      "                                            random_state=42))])\n",
      "F1 Score:  0.6\n",
      "Precision Score:  0.631578947368421\n",
      "Recall Score:  0.5714285714285714\n",
      "Accuracy:  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "best_gb = gb_clf.best_estimator_\n",
    "preds =  best_gb.predict(X_test)\n",
    "\n",
    "print('Best GradientBoostingClassifier Metrics')\n",
    "print('---------------------------------------')\n",
    "print('Best Model:', best_gb)\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF Hyperparameter Tune\n",
    "RANDOM_STATE = 42\n",
    "rf_clf = grid_cv_model(\n",
    "     X=X_train,\n",
    "     y=y_train,\n",
    "     model= RandomForestClassifier(class_weight = 'balanced'),\n",
    "     params={\n",
    "         \"random_state\": [RANDOM_STATE],\n",
    "         \"n_estimators\": np.arange(1,100,1),\n",
    "         \"max_features\":['sqrt', 'log2', None], \n",
    "         \"criterion\": ['gini', 'entropy', 'log_loss']\n",
    "     },\n",
    "     cv=5,\n",
    "     scoring='recall'\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForestClassifier Metrics\n",
      "---------------------------------------\n",
      "Best Model: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(class_weight='balanced',\n",
      "                                        max_features=None, n_estimators=7,\n",
      "                                        random_state=42))])\n",
      "F1 Score:  0.4444444444444444\n",
      "Precision Score:  0.5333333333333333\n",
      "Recall Score:  0.38095238095238093\n",
      "Accuracy:  0.8611111111111112\n"
     ]
    }
   ],
   "source": [
    "best_rf = rf_clf.best_estimator_\n",
    "preds =  best_rf.predict(X_test)\n",
    "\n",
    "print('Best RandomForestClassifier Metrics')\n",
    "print('---------------------------------------')\n",
    "print('Best Model:', best_rf)\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR Hyperparameter Tune\n",
    "RANDOM_STATE = 42\n",
    "lr_clf = grid_cv_model(\n",
    "     X=X_train,\n",
    "     y=y_train,\n",
    "     model= LogisticRegression(class_weight='balanced'),\n",
    "     params={\n",
    "         \"random_state\": [RANDOM_STATE],\n",
    "         \"penalty\": ['l2'],\n",
    "         \"solver\": ['lbfgs', 'liblinear'], \n",
    "         \"C\": [1, 5, 10, 100, 1000], \n",
    "         \"max_iter\": np.arange(10000, 11000, 100)\n",
    "     },\n",
    "     cv=5,\n",
    "     scoring='recall'\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LogisticRegression Metrics\n",
      "---------------------------------------\n",
      "Best Model: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 LogisticRegression(C=1000, class_weight='balanced',\n",
      "                                    max_iter=10000, random_state=42))])\n",
      "F1 Score:  0.5\n",
      "Precision Score:  0.4\n",
      "Recall Score:  0.6666666666666666\n",
      "Accuracy:  0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "best_lr = lr_clf.best_estimator_\n",
    "preds = best_lr.predict(X_test)\n",
    "\n",
    "print('Best LogisticRegression Metrics')\n",
    "print('---------------------------------------')\n",
    "print('Best Model:', best_lr)\n",
    "print('F1 Score: ', f1_score(y_test, preds))\n",
    "print('Precision Score: ', precision_score(y_test, preds))\n",
    "print('Recall Score: ', recall_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rb_classifier.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(best_gb, 'rb_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
