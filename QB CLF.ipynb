{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/736867005.py:2: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('Data/Final Dataset.csv')\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/736867005.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  coaching_data = pd.read_csv('Data/Coaching Data.csv', skiprows = [0,1], skipfooter = 202)\n"
     ]
    }
   ],
   "source": [
    "#Load Dataset and Coaching Data\n",
    "data = pd.read_csv('Data/Final Dataset.csv')\n",
    "\n",
    "coaching_data = pd.read_csv('Data/Coaching Data.csv', skiprows = [0,1], skipfooter = 202)\n",
    "coaching_data = coaching_data.rename(columns = {'FBS Team': 'Team'})\n",
    "coaching_data = coaching_data[['Team','2019','2020','2021','2022','2023','2024']]\n",
    "coaching_data = coaching_data.melt(id_vars='Team', var_name = 'Season', value_name = 'Coach')\n",
    "coaching_data['Season'] = coaching_data['Season'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Coaching Change Function to Add Coaching Change Column to Data\n",
    "def coach_change(row, data):\n",
    "\n",
    "    team = str(row.Team)\n",
    "    season = int(row.Season)\n",
    "\n",
    "    try:\n",
    "    \n",
    "        curr_coach = data[(data['Team'] == team) & (data['Season'] == season)]['Coach']\n",
    "        curr_coach = curr_coach[curr_coach.index[0]]\n",
    "        next_coach = data[(data['Team'] == team) & (data['Season'] == season + 1)]['Coach']\n",
    "        next_coach = next_coach[next_coach.index[0]]\n",
    "\n",
    "        if curr_coach != next_coach:\n",
    "            return 'Yes'\n",
    "        return 'No'\n",
    "        \n",
    "    \n",
    "    except:\n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add coaching change info to data\n",
    "data['Coach Change'] = data.apply(lambda x: coach_change(x, coaching_data), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RB', 'WR', 'QB', 'TE', 'LB', 'DB', 'OL', 'DL', 'CB', 'S', 'PK',\n",
       "       'LS', 'P', 'DT', 'DE', 'FB', 'C', 'OT', 'G', 'NT', 'ATH', 'OLB',\n",
       "       '?'], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = data.Position.unique()\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add recruiting info\n",
    "for i,year in enumerate(['2015','2016','2017','2018', '2019','2020', '2021', '2022', '2023']):\n",
    "    file = pd.read_csv('Data/Player Recruit Ranking/' + year + '.csv')\n",
    "    file.rename(columns = {'AthleteId': 'PlayerId', 'Year': 'Class of'}, inplace = True)\n",
    "    #file.drop(columns = ['Year', 'Rating', 'Ranking'], inplace = True)\n",
    "    #file.drop(columns = ['Year'], inplace = True)\n",
    "    data = data.merge(file, on = 'PlayerId', how = 'left', suffixes = [None, '_' + str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Columns\n",
    "for i in range(0,9):\n",
    "    data['Stars'] = data['Stars'].combine_first(data['Stars_' + str(i)])\n",
    "    data.drop(columns = ['Stars_' + str(i)], inplace = True)\n",
    "for i in range(1,9):\n",
    "    data['Rating'] = data['Rating'].combine_first(data['Rating_' + str(i)])\n",
    "    data['Ranking'] = data['Ranking'].combine_first(data['Ranking_' + str(i)])\n",
    "    data['Class of'] = data['Class of'].combine_first(data['Class of_' + str(i)])\n",
    "    data.drop(columns = ['Rating_' + str(i)], inplace = True)\n",
    "    data.drop(columns = ['Ranking_' + str(i)], inplace = True)\n",
    "    data.drop(columns = ['Class of_' + str(i)], inplace = True)\n",
    "\n",
    "data['Yr'] = data['Season'] - data['Class of'] + 1\n",
    "data.drop(columns = ['Class of'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_groups = {'OL':['OL', 'NT', 'OT', 'G', 'C','FB'],\n",
    "                   'TE':['TE'],\n",
    "                   'QB':['QB'],\n",
    "                   'RB':['RB'],\n",
    "                   'WR':['WR'],\n",
    "                   'DL':['DT', 'DE', 'DL'],\n",
    "                   'DB':['DB', 'CB', 'S'],\n",
    "                   'LB':['LB'],\n",
    "                   'ST':['LS', 'P', 'PK']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Data into Position Groups\n",
    "data_sets = {}\n",
    "for key in position_groups.keys():\n",
    "    data_sets[key] = data.copy()[data.copy()['Position'].isin(position_groups[key])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with QB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = data_sets['QB'].copy().drop(columns = ['PositionId', 'ConferenceId', 'TeamId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engineer PCT Features\n",
    "qb['Pct_Team_Pass_Yds'] = qb['YDS']/qb['Team netPassingYards']\n",
    "qb['Pct_Team_Pass_Attempts'] = qb['ATT']/qb['Team passAttempts']\n",
    "qb['Pct_Team_Pass_TDs'] = qb['TD']/qb['Team passingTDs']\n",
    "qb['Pct_Team_Pass_Completions'] = qb['COMPLETIONS']/qb['Team passCompletions']\n",
    "qb['Pct_Team_Ints'] = qb['INT']/qb['Team passesIntercepted']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Improve Function\n",
    "def improve(row, column, data):\n",
    "    try: \n",
    "        id = int(row['PlayerId'])\n",
    "        season = int(row['Season'])\n",
    "        column = column\n",
    "        imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
    "\n",
    "        if imp:\n",
    "            return 'Yes' \n",
    "        return 'No'\n",
    "    except:\n",
    "        return 'Yes'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n",
      "/var/folders/5r/dp58bhsd7wvbt6d73cxcyj840000gn/T/ipykernel_93516/3934428695.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  imp = float(data[(data['PlayerId'] == id) & (data['Season'] == season)][column]) > float(data[(data['PlayerId'] == id) & (data['Season'] == season-1)][column])\n"
     ]
    }
   ],
   "source": [
    "#Engineer Improve Features\n",
    "feats_to_improve = ['Usage Overall', 'Usage Pass', 'Usage Rush', 'Usage FirstDown','Usage SecondDown', 'Usage ThirdDown', 'Usage StandardDowns',\n",
    "       'Usage PassingDowns','ATT', 'AVG','COMPLETIONS','INT','LONG','PCT','TD','YDS', 'YPA','Pct_Team_Pass_Yds', 'Pct_Team_Pass_Attempts', 'Pct_Team_Pass_TDs',\n",
    "       'Pct_Team_Pass_Completions', 'Pct_Team_Ints']\n",
    "\n",
    "for feat in feats_to_improve:\n",
    "    qb[feat+'_improve'] = qb.apply(lambda x: improve(x, feat, qb), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify Relevant Columns\n",
    "#No team stats added as of right now\n",
    "rel_feats = ['Usage Overall', 'Usage Pass', 'Usage Rush', 'Usage FirstDown','Usage SecondDown', 'Usage ThirdDown', 'Usage StandardDowns',\n",
    "             'Usage PassingDowns','ATT','COMPLETIONS','INT','LONG','PCT','TD','YDS', 'YPA','Pct_Team_Pass_Yds', 'Pct_Team_Pass_Attempts', 'Pct_Team_Pass_TDs',\n",
    "             'Pct_Team_Pass_Completions', 'Pct_Team_Ints', 'Usage Overall_improve',\n",
    "             'Usage Pass_improve', 'Usage Rush_improve', 'Usage FirstDown_improve',\n",
    "             'Usage SecondDown_improve', 'Usage ThirdDown_improve',\n",
    "             'Usage StandardDowns_improve', 'Usage PassingDowns_improve',\n",
    "             'ATT_improve', 'AVG_improve', 'COMPLETIONS_improve', 'INT_improve',\n",
    "             'LONG_improve', 'PCT_improve', 'TD_improve', 'YDS_improve',\n",
    "             'YPA_improve', 'Pct_Team_Pass_Yds_improve',\n",
    "             'Pct_Team_Pass_Attempts_improve', 'Pct_Team_Pass_TDs_improve',\n",
    "             'Pct_Team_Pass_Completions_improve', 'Pct_Team_Ints_improve', 'Team','Conference','Position','Yr','Stars', 'Coach Change', 'Ranking', 'Rating', 'Transfer_Portal']\n",
    "\n",
    "\n",
    "#Get rid of 2019, narrow down to relevant features\n",
    "qb = qb[qb['Season'] != 2019]\n",
    "qb = qb[rel_feats]\n",
    "#Encode Label Columns\n",
    "qb['Transfer_Portal'] = np.where(qb['Transfer_Portal'].values == 'Yes', 1, 0)\n",
    "\n",
    "#Convert Yr and Stars to Categorical Variables\n",
    "qb['Yr'] = qb['Yr'].astype('str')\n",
    "qb['Stars'] = qb['Stars'].astype('str')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into Training and Testing Data\n",
    "X = qb.drop(columns=['Transfer_Portal'])\n",
    "y = qb['Transfer_Portal']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)\n",
    "\n",
    "#Specify the Numerical Features and Categorical Features\n",
    "categorical = ['Usage Overall_improve',\n",
    "               'Usage Pass_improve', 'Usage Rush_improve', 'Usage FirstDown_improve',\n",
    "               'Usage SecondDown_improve', 'Usage ThirdDown_improve',\n",
    "               'Usage StandardDowns_improve', 'Usage PassingDowns_improve',\n",
    "               'ATT_improve', 'AVG_improve', 'COMPLETIONS_improve', 'INT_improve',\n",
    "               'LONG_improve', 'PCT_improve', 'TD_improve', 'YDS_improve',\n",
    "               'YPA_improve', 'Pct_Team_Pass_Yds_improve',\n",
    "               'Pct_Team_Pass_Attempts_improve', 'Pct_Team_Pass_TDs_improve',\n",
    "               'Pct_Team_Pass_Completions_improve', 'Pct_Team_Ints_improve', 'Team','Conference','Position','Yr','Stars', 'Coach Change']\n",
    "\n",
    "numerical = [feat for feat in X.columns if feat not in categorical]\n",
    "\n",
    "#Pipeline to SimpleImpute and OneHot Encode Categorical Features (Training data only)\n",
    "impute_encode = Pipeline([('impute',SimpleImputer(strategy='constant',fill_value='N/A')), ('encode',OneHotEncoder(handle_unknown='ignore'))])\n",
    "column_transform = ColumnTransformer([('cat_encode', impute_encode, categorical), ('numerical_pass', SimpleImputer(strategy='constant',fill_value=0),numerical)])\n",
    "\n",
    "X_train = column_transform.fit_transform(X_train)\n",
    "\n",
    "#Fit Pipeline ColumnTransformer to testing features\n",
    "X_test = column_transform.transform(X_test)\n",
    "\n",
    "#SMOTE Balancing of Training Data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores:\n",
      "0.7467362435940597\n",
      "0.7837775458956131\n",
      "0.7475913415001495\n",
      " \n",
      "Precision Scores:\n",
      "0.7467362435940597\n",
      "0.7558223866790009\n",
      "0.7983031674208145\n",
      " \n",
      "Recall Scores:\n",
      "0.7318692321889996\n",
      "0.8311387966039128\n",
      "0.713686323366556\n"
     ]
    }
   ],
   "source": [
    "#CV Models w/ Training Data\n",
    "cv = KFold(n_splits = 5)\n",
    "\n",
    "def classifiers():\n",
    "    gb_clf = make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=42))\n",
    "    SVM_clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    forest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    gb_f1 = cross_val_score(gb_clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    SVM_f1 = cross_val_score(SVM_clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "    forest_f1 = cross_val_score(forest_clf, X_train, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "    gb_pre = cross_val_score(gb_clf, X_train, y_train, cv=cv, scoring='precision')\n",
    "    SVM_pre = cross_val_score(SVM_clf, X_train, y_train, cv=cv, scoring='precision')\n",
    "    forest_pre = cross_val_score(forest_clf, X_train, y_train, cv=cv, scoring='precision')\n",
    "\n",
    "    gb_re = cross_val_score(gb_clf, X_train, y_train, cv=cv, scoring='recall')\n",
    "    SVM_re = cross_val_score(SVM_clf, X_train, y_train, cv=cv, scoring='recall')\n",
    "    forest_re = cross_val_score(forest_clf, X_train, y_train, cv=cv, scoring='recall')\n",
    "\n",
    "    print('F1 Scores:')\n",
    "    print(gb_f1.mean())\n",
    "    print(SVM_f1.mean())\n",
    "    print(forest_f1.mean())\n",
    "    print(' ')\n",
    "    print('Precision Scores:')\n",
    "    print(gb_f1.mean())\n",
    "    print(SVM_pre.mean())\n",
    "    print(forest_pre.mean())\n",
    "    print(' ')\n",
    "    print('Recall Scores:')\n",
    "    print(gb_re.mean())\n",
    "    print(SVM_re.mean())\n",
    "    print(forest_re.mean())\n",
    "\n",
    "classifiers()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base GradientBoostingClassifier Metrics\n",
      "---------------------------------------\n",
      "F1 Score:  0.8154114886770417\n",
      "Precision Score:  0.813318707984453\n",
      "Recall Score:  0.8327137546468402\n",
      "Accuracy:  0.8327137546468402\n"
     ]
    }
   ],
   "source": [
    "#Evaluate trained model on test data\n",
    "#Use 'weighted' f1 score, recall, precision since data is imbalanced\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print('Base GradientBoostingClassifier Metrics')\n",
    "print('---------------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds, average='weighted'))\n",
    "print('Precision Score: ', precision_score(y_test, preds, average='weighted'))\n",
    "print('Recall Score: ', recall_score(y_test, preds, average = 'weighted'))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base RandomForestClassifier Metrics\n",
      "-----------------------------------\n",
      "F1 Score:  0.793678481782571\n",
      "Precision Score:  0.8070074102598281\n",
      "Recall Score:  0.828996282527881\n",
      "Accuracy:  0.828996282527881\n"
     ]
    }
   ],
   "source": [
    "#Evaluate trained model on test data\n",
    "#Use 'weighted' f1 score, recall, precision since data is imbalanced\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, class_weight = 'balanced')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print('Base RandomForestClassifier Metrics')\n",
    "print('-----------------------------------')\n",
    "print('F1 Score: ', f1_score(y_test, preds, average='weighted'))\n",
    "print('Precision Score: ', precision_score(y_test, preds, average='weighted'))\n",
    "print('Recall Score: ', recall_score(y_test, preds, average = 'weighted'))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch/Optimize/Hyperparameter Tune"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
